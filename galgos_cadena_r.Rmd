---
title: "GALGOS Cadena en R"
output: html_notebook
---

INPUT: datasets preparados, 
OUTPUT: análisis, datasets elaborados y modelos

Analisis de datasets en proyecto GALGOS.

#### Conexion a BBDD MySQL
```{r}
library(RMySQL)
library(DBI)

leerDesdeBaseDatosYEscribirCSV <- function(){
  
  # ---------------Conexion a BBDD ------------
  #Conexiones ya abiertas
  conexiones_abiertas <- dbListConnections(MySQL())
  #Cerramos las conexiones abiertas
  #dbDisconnect(dbListConnections(MySQL())[[1]])

  mydb = dbConnect(MySQL(), user = 'root', password = 'datos1986', dbname = 'datos_desa', host = 'localhost')
  on.exit(dbDisconnect(mydb))
  #dbListTables(mydb)  #Todas las tablas que tengo
  
  
  # ------------- Features (INPUT) -----------------------
  pasado_f_rs <- dbSendQuery(mydb, "SELECT * FROM datos_desa.tb_ds_pasado_train_features_TOTAL LIMIT 10000")
  typeof(pasado_f_rs)
  pasado_f <- dbFetch(pasado_f_rs, n = -1)
  #dbClearResult(pasado_f_rs)

  #EXCEPCION Quito columna mes
  mes_indice <- which( colnames(pasado_f) == "mes_norm" )
  pasado_f <- pasado_f[, -mes_indice]
  
  attach(pasado_f)
  names(pasado_f)
  print(paste("FEATURE MATRIX: ", nrow(pasado_f), "x", ncol(pasado_f)))
  print(typeof(pasado_f)) #Formato: lista

  
  # -------------------- Targets (INPUT) -----------------
  pasado_t_rs <- dbSendQuery(mydb, "SELECT * FROM datos_desa.tb_ds_pasado_train_targets_TOTAL LIMIT 10000")
  typeof(pasado_t_rs)
  pasado_t <- dbFetch(pasado_t_rs, n = -1)
  #dbClearResult(pasado_t_rs)
  attach(pasado_t)
  names(pasado_t)
  print(paste("TARGET MATRIX: ", nrow(pasado_t), "x", ncol(pasado_t)))
  print(typeof(pasado_t))


  # ----- Escritura a fichero CSV (para poder trabajar en PCs donde no tengo montada la BBDD con datos) ----
  print(getwd())
  write.csv(x = pasado_f, file = 'input_features.csv', append = FALSE, quote = TRUE, sep = '|', eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE, qmethod = c("escape", "double"), fileEncoding = "UTF-8")
  write.csv(x = pasado_t, file = 'input_targets.csv', append = FALSE, quote = TRUE, sep = '|', eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE, qmethod = c("escape", "double"), fileEncoding = "UTF-8")

}

#Si no tengo acceso a BBDD local, debo tener esto siempre comentado para no pisar el actual CSV
#leerDesdeBaseDatosYEscribirCSV()
```

#### Lectura de ficheros CSV (features y targets)
```{r}
print(getwd())
pasado_f <- read.csv('input_features.csv')
pasado_t <- read.csv('input_targets.csv')
```

## ANALISIS PRELIMINAR DE DATOS
```{r}
#Juntar FEATURES y TARGET
pasado_ft <- cbind(pasado_f, pasado_t)

head(pasado_ft)
boxplot(pasado_ft, cex.axis=0.5) 
```
Vemos que hay variables con outliers y otras leptocúrticas (apretadas en torno a la media).
```{r}
#summary(pasado_ft)
lapply(pasado_ft, summary)
```

Creamos un modelo para cada tipo de DISTANCIA, para usar sólo las columnas útiles para esa distancia:
```{r}
col_cortas <- c("vel_real_cortas_mediana_norm", "vel_real_cortas_max_norm", "vel_going_cortas_mediana_norm", "vel_going_cortas_max_norm")
col_medias <- c("vel_real_longmedias_mediana_norm", "vel_real_longmedias_max_norm", "vel_going_longmedias_mediana_norm", "vel_going_longmedias_max_norm")
col_largas <- c("vel_real_largas_mediana_norm", "vel_real_largas_max_norm", "vel_going_largas_mediana_norm", "vel_going_largas_max_norm")

#QUITAR las COLUMNAS que no son UTILES para esa DISTANCIA
pasado_ft_cortas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_medias | names(pasado_ft) %in% col_largas)] )
colSums(is.na(pasado_ft_cortas)) #comprobamos que no hay missing data
indices_sin_na_cortas <- as.numeric( na.action(pasado_ft_cortas) )
paste("CORTAS:", nrow(pasado_ft_cortas), "x", ncol(pasado_ft_cortas))

pasado_ft_medias <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_largas)] )
colSums(is.na(pasado_ft_medias)) #comprobamos que no hay missing data
indices_sin_na_medias <- as.numeric( na.action(pasado_ft_medias) )
paste("MEDIAS:", nrow(pasado_ft_medias), "x", ncol(pasado_ft_medias))

pasado_ft_largas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_medias)] )
colSums(is.na(pasado_ft_largas)) #comprobamos que no hay missing data
indices_sin_na_largas <- as.numeric( na.action(pasado_ft_largas) )
paste("LARGAS:", nrow(pasado_ft_largas), "x", ncol(pasado_ft_largas))
```


Analisis:
```{r}
# SELECCION DEL MODELO DE FORMA MANUAL
analisis_modelos <- function(matrizentrada){
  library(e1071) #SVM
  library(rpart) #Regression trees
  
  ## Split en Datasets (train y test)
  index     <- 1:nrow(matrizentrada)
  tercio <- trunc(0.30 * length(index)) #70%-TRAIN, 30%-Test
  testindex <- sample(index, tercio, replace = FALSE, prob = NULL)
  testset   <- na.omit(matrizentrada[testindex,]) #TEST Quita las filas que tengan ALGUN valor NA
  trainset  <- na.omit(matrizentrada[-testindex,])#TRAIN Quita las filas que tengan ALGUN valor NA
  
  #Columna TARGET
  indice_target <- which( colnames(trainset) == "TARGET" )
  
  ## svm (MAQUINAS VECTOR SOPORTE) para REGRESIÓN NO LINEAL
  svm.model <- svm(formula = TARGET ~ ., data = trainset, cost = 1000, gamma = 0.0001)
  svm.pred  <- predict(svm.model, testset[,-indice_target])
  svm_error <- crossprod(svm.pred - testset[,indice_target]) / length(testindex)
  svm_error
  
  ## rpart (ARBOLES DE REGRESION) para REGRESIÓN NO LINEAL
  rpart.model <- rpart(formula = TARGET ~ ., data = trainset)
  rpart.pred  <- predict(rpart.model, testset[,-indice_target])
  rpart_error <- crossprod(rpart.pred - testset[,indice_target]) / length(testindex)
  rpart_error
  
  if ( svm_error < rpart_error ) {
    print("Gana modelo SVM")
    return(svm.model)
  } else {
    print("Gana modelo RPART")
    return( rpart.model )
  }
}

# SELECCION DEL MODELO USANDO SUPERLEARNER
analisis_modelos_superlearner <- function(matrizentrada){
  
  library("SuperLearner")
  
  ## Split en Datasets (train y test)
  index     <- 1:nrow(matrizentrada)
  tercio <- trunc(0.30 * length(index)) #70%-TRAIN, 30%-Test
  testindex <- sample(index, tercio, replace = FALSE, prob = NULL)
  testset   <- na.omit(matrizentrada[testindex,]) #TEST Quita las filas que tengan ALGUN valor NA
  trainset  <- na.omit(matrizentrada[-testindex,])#TRAIN Quita las filas que tengan ALGUN valor NA
  
  #Columna TARGET
  indice_target <- which( colnames(trainset) == "TARGET" )
  
  #Features y target de los datasets de TRAIN y TEST
  x_train <- subset(trainset, select = -indice_target)
  y_train <- trainset$TARGET
  x_test <- subset(testset, select = -indice_target)
  y_test <- testset$TARGET
  
  #Estructura y dimensiones de los datos
  #str(x_train)
  #dim(x_train)
  
  #MODELOS DISPONIBLES:
  #listWrappers()
  
  set.seed(150)
  
  algoritmosPredictivosTodos <- list("SL.bartMachine", "SL.bayesglm",  "SL.biglasso",  "SL.caret",
                                      "SL.caret.rpart",  "SL.cforest", "SL.dbarts",  "SL.earth",
                                      "SL.extraTrees",  "SL.gam",  "SL.gbm",  "SL.glm",  "SL.glm.interaction",
                                      "SL.glmnet",  "SL.ipredbagg",   "SL.kernelKnn",  "SL.knn",
                                      "SL.ksvm",  "SL.lda",  "SL.leekasso",  "SL.lm",  "SL.loess",
                                      "SL.logreg",  "SL.mean",  "SL.nnet",  "SL.nnls",  "SL.polymars",
                                      "SL.qda",  "SL.randomForest",  "SL.ranger",  "SL.ridge",  "SL.rpart",
                                      "SL.rpartPrune",  "SL.speedglm",  "SL.speedlm",  "SL.step",
                                      "SL.stepAIC",  "SL.step.forward",  "SL.step.interaction",  "SL.svm",
                                      "SL.template",  "SL.xgboost")
  
  #RECURSOS
  #options(java.parameters = '-Xmx5g') #Memoria 5GB
  
  #---------------------HYPERPARAMETROS--------------
  #Explicacion: override default parameters of some functions to fit better
  mtry_seq <- floor(sqrt(ncol(x_train)) * c(1, 2)) #MTRY: how many features are randomly chosen within each decision tree node
  print(mtry_seq)
  
  print('Learners modificados (con hyperparametros):')
  learners_rf <- create.Learner(base_learner = "SL.randomForest",
                               params = list(),
                               tune = list(mtry = mtry_seq))
  print(learners_rf)
  
  #--------------------------------------------------------
  print('Algoritmos usados:')
  algoritmosPredictivosUsados <- list(learners_rf$names, "SL.ridge")
  algoritmosPredictivosUsados
  
  
  #PENDIENTE: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html#test-algorithm-with-multiple-hyperparameter-settings
  
  
  #--------------------------------------------------------------- 
  print('UNICORE (con cross validation)...')
  modelo_super <- SuperLearner(Y = y_train, X = x_train, newX = x_test,
                               family = gaussian(), 
                               SL.library = algoritmosPredictivosUsados, method = "method.NNLS",
                               id = NULL, verbose = FALSE,
                               control = list(), cvControl = list(), obsWeights = NULL, env = parent.frame())
  
  summary(modelo_super)
  
  
  #------------------------------------------------------------
  print('MULTICORE (con cross validation)...')
  print('Se puede usar la libreria SNOW (Windows, Linux; pero dificil) o multicore (Linux).')
  num_cores_disponibles = RhpcBLASctl::get_num_cores()
  num_cores_usados <- (num_cores-1)
  print(paste('Uso ', num_cores_usados, ' cores de ', num_cores_disponibles, ' cores disponibles'))
  options(mc.cores = num_cores_usados) #Uso todas las CPUs (menos una, para dejar libre el PC para trabajar)
  getOption("mc.cores") #En Linux, comprobamos su estamos usando todos los cores

  # We need to set a different type of seed that works across cores.
  # Otherwise the other cores will go rogue and we won't get repeatable results.
  # This version is for the "multicore" parallel system in R.
  set.seed(1, "L'Ecuyer-CMRG")

  # While this is running check CPU using in Activity Monitor / Task Manager.
  print('SUPERLEARNER con MULTICORE:')
  system.time({
    modelo_multicore_con_cv=CV.SuperLearner(Y = y_train, X = x_train, family = gaussian(), V = 2,
                          parallel = "multicore",
                          SL.library = algoritmosPredictivosUsados)
  })
  summary(modelo_multicore_con_cv)
  
  
  #------------------------------------------------------------------
  print('MULTICORE (sin cross validation)...')
  # Set multicore compatible seed.
  set.seed(1, "L'Ecuyer-CMRG")
  # Fit the SuperLearner.
  modelo_multicore_sin_cv = mcSuperLearner(Y = y_train, X = x_train, family = gaussian(),
                    SL.library = algoritmosPredictivosUsados)
  summary(modelo_multicore_sin_cv)
  
  # ----------------------------------------------
  
  #CROSS_VALIDATION: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html#fit-ensemble-with-external-cross-validation
  
  
  #----------- PREDICCION sobre dataset TEST ----
  y_test_predicho_objeto <- predict(modelo_super, x_test, onlySL = TRUE) #No usa los que tienen peso =0
  str(y_test_predicho_objeto)
  summary(y_test_predicho_objeto$library.predict)
  
  #Graficos de la prediccion
  library(ggplot2)
  qplot(y_test_predicho_objeto$pred[, 1]) + theme_minimal() #Histograma de los valores predichos
  qplot(y_test, y_test_predicho_objeto$pred[, 1]) + theme_minimal() #Scatterplot
  
  #ROC (Solo para CLASIFICACION BINARIA)
  # Curva ROC (AUC, Area Under Curve): AUC can range from 0.5 (no better than chance) to 1.0 (perfect)
  #pred_rocr <- ROCR::prediction(predictions=y_test_predicho_objeto$pred, labels = y_test, label.ordering = NULL)
  #auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
  #print(auc)
  #---------------------------
  
  return(modelo_super)
}



############### Para cada distancia, obtengo el mejor modelo #################
#modelo_cortas <- analisis_modelos(pasado_ft_cortas)
#modelo_medias <- analisis_modelos(pasado_ft_medias)
#modelo_largas <- analisis_modelos(pasado_ft_largas)

modelo_cortas <- analisis_modelos_superlearner(pasado_ft_cortas)
#modelo_medias <- analisis_modelos_superlearner(pasado_ft_medias)
#modelo_largas <- analisis_modelos_superlearner(pasado_ft_largas)

```

Analisis de los modelos ganadores:
```{r}
#------------------- Analisis de los modelos ganadores
#Tiempo de ejecucion
modelo_cortas$times$everything
#El riesgo del MEJOR modelo (gana el que tiene MENOR riesgo)
riesgo_submodelo_ganador <- modelo_cortas$cvRisk[which.min(modelo_cortas$cvRisk)]
#Resumen
summary(modelo_cortas)
#Riesgo (risk) y peso (coef) de los submodelos utilizados
modelo_cortas
#------------------------------------
```

Prediccion del futuro usando los modelos ganadores:
```{r}
print('meter prediccion sobre X futuro...')
```


