---
title: "GALGOS Cadena en R"
output: html_notebook
---

INPUT: datasets preparados, 
OUTPUT: análisis, datasets elaborados y modelos

Analisis de datasets en proyecto GALGOS.

#### Conexion a BBDD MySQL
```{r}
library(RMySQL)
library(DBI)

#' Conexion a base de datos para LECTURA MASIVA y escritura a CSV.
#'
#' @return
#' @export
#'
#' @examples
leerDesdeBaseDatosYEscribirCSV <- function(){
  
  # ---------------Conexion a BBDD ------------
  #Conexiones ya abiertas
  conexiones_abiertas <- dbListConnections(MySQL())
  #Cerramos las conexiones abiertas
  #dbDisconnect(dbListConnections(MySQL())[[1]])

  mydb = dbConnect(MySQL(), user = 'root', password = 'datos1986', dbname = 'datos_desa', host = 'localhost')
  on.exit(dbDisconnect(mydb))
  #dbListTables(mydb)  #Todas las tablas que tengo
  
  
  # ------------- Features (INPUT) -----------------------
  pasado_f_rs <- dbSendQuery(mydb, "SELECT * FROM datos_desa.tb_ds_pasado_train_features_TOTAL LIMIT 1000")
  typeof(pasado_f_rs)
  pasado_f <- dbFetch(pasado_f_rs, n = -1)
  #dbClearResult(pasado_f_rs)

  #EXCEPCION Quito columna mes
  mes_indice <- which( colnames(pasado_f) == "mes_norm" )
  pasado_f <- pasado_f[, -mes_indice]
  
  attach(pasado_f)
  names(pasado_f)
  print(paste("FEATURE MATRIX: ", nrow(pasado_f), "x", ncol(pasado_f)))
  print(typeof(pasado_f)) #Formato: lista

  
  # -------------------- Targets (INPUT) -----------------
  pasado_t_rs <- dbSendQuery(mydb, "SELECT * FROM datos_desa.tb_ds_pasado_train_targets_TOTAL LIMIT 1000")
  typeof(pasado_t_rs)
  pasado_t <- dbFetch(pasado_t_rs, n = -1)
  #dbClearResult(pasado_t_rs)
  attach(pasado_t)
  names(pasado_t)
  print(paste("TARGET MATRIX: ", nrow(pasado_t), "x", ncol(pasado_t)))
  print(typeof(pasado_t))


  # ----- Escritura a fichero CSV (para poder trabajar en PCs donde no tengo montada la BBDD con datos) ----
  print(getwd())
  write.csv(x = pasado_f, file = 'input_features.csv', append = FALSE, quote = TRUE, sep = '|', eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE, qmethod = c("escape", "double"), fileEncoding = "UTF-8")
  write.csv(x = pasado_t, file = 'input_targets.csv', append = FALSE, quote = TRUE, sep = '|', eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE, qmethod = c("escape", "double"), fileEncoding = "UTF-8")

}

#Si no tengo acceso a BBDD local, debo tener esto siempre comentado para no pisar el actual CSV
leerDesdeBaseDatosYEscribirCSV()
```

#### Lectura de ficheros CSV (features y targets)
```{r}
print(getwd())
pasado_f <- read.csv('input_features.csv')
pasado_t <- read.csv('input_targets.csv')
```

## ANALISIS PRELIMINAR DE DATOS
```{r}
#Juntar FEATURES y TARGET
pasado_ft <- cbind(pasado_f, pasado_t)

head(pasado_ft)
boxplot(pasado_ft, cex.axis=0.5) 
```
Vemos que hay variables con outliers y otras leptocúrticas (apretadas en torno a la media).
```{r}
#summary(pasado_ft)
lapply(pasado_ft, summary)
```

Creamos un modelo para cada tipo de DISTANCIA, para usar sólo las columnas útiles para esa distancia:
```{r}
col_cortas <- c("vel_real_cortas_mediana_norm", "vel_real_cortas_max_norm", "vel_going_cortas_mediana_norm", "vel_going_cortas_max_norm")
col_medias <- c("vel_real_longmedias_mediana_norm", "vel_real_longmedias_max_norm", "vel_going_longmedias_mediana_norm", "vel_going_longmedias_max_norm")
col_largas <- c("vel_real_largas_mediana_norm", "vel_real_largas_max_norm", "vel_going_largas_mediana_norm", "vel_going_largas_max_norm")

#QUITAR las COLUMNAS que no son UTILES para esa DISTANCIA
pasado_ft_cortas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_medias | names(pasado_ft) %in% col_largas)] )
colSums(is.na(pasado_ft_cortas)) #comprobamos que no hay missing data
indices_sin_na_cortas <- as.numeric( na.action(pasado_ft_cortas) )
paste("CORTAS:", nrow(pasado_ft_cortas), "x", ncol(pasado_ft_cortas))

pasado_ft_medias <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_largas)] )
colSums(is.na(pasado_ft_medias)) #comprobamos que no hay missing data
indices_sin_na_medias <- as.numeric( na.action(pasado_ft_medias) )
paste("MEDIAS:", nrow(pasado_ft_medias), "x", ncol(pasado_ft_medias))

pasado_ft_largas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_medias)] )
colSums(is.na(pasado_ft_largas)) #comprobamos que no hay missing data
indices_sin_na_largas <- as.numeric( na.action(pasado_ft_largas) )
paste("LARGAS:", nrow(pasado_ft_largas), "x", ncol(pasado_ft_largas))
```

Analisis de modelos usando SuperLearner:
```{r}
#' SELECCION DEL MODELO USANDO SUPERLEARNER
#'
#' @param matrizentrada 
#'
#' @return
#' @export
#'
#' @examples
analisis_modelos_superlearner <- function(matrizentrada){
  
  library("SuperLearner")
  library(nnls)
library(nnet)
library(randomForest)
library(ggplot2)
library(parallel)
  
  #Crear datasets features+target para train y test
  index     <- 1:nrow(matrizentrada)
tercio <- trunc(0.30 * length(index)) #70%-TRAIN, 30%-Test
testindex <- sample(index, tercio, replace = FALSE, prob = NULL)
testset   <- na.omit(matrizentrada[testindex,])
trainset  <- na.omit(matrizentrada[-testindex,])

indice_target <- which( colnames(trainset) == "TARGET" ) #Columna TARGET
x_train <- subset(trainset, select = -indice_target)
y_train <- trainset$TARGET
x_test <- subset(testset, select = -indice_target)
y_test <- testset$TARGET
  
print( paste( "matrizentrada=",nrow(matrizentrada), "x", ncol(matrizentrada) ) )
print( paste( "testset=",nrow(testset), "x", ncol(testset) ) )
print( paste( "trainset=",nrow(trainset), "x", ncol(trainset) ) )
print( paste( "x_train=",nrow(x_train), "x", ncol(x_train) ) )
print( paste( "y_train=",length(y_train) ) )
print( paste( "x_test=",nrow(x_test), "x", ncol(x_test) ) )
print( paste( "y_test=",length(y_test) ) )
  
  #listWrappers()  #MODELOS DISPONIBLES en libreria SuperLearner:
  
  set.seed(150)
  
  algoritmosPredictivosTodos <- list("SL.bartMachine", "SL.bayesglm",  "SL.biglasso",  "SL.caret",
                                      "SL.caret.rpart",  "SL.cforest", "SL.dbarts",  "SL.earth",
                                      "SL.extraTrees",  "SL.gam",  "SL.gbm",  "SL.glm",  "SL.glm.interaction",
                                      "SL.glmnet",  "SL.ipredbagg",   "SL.kernelKnn",  "SL.knn",
                                      "SL.ksvm",  "SL.lda",  "SL.leekasso",  "SL.lm",  "SL.loess",
                                      "SL.logreg",  "SL.mean",  "SL.nnet",  "SL.nnls",  "SL.polymars",
                                      "SL.qda",  "SL.randomForest",  "SL.ranger",  "SL.ridge",  "SL.rpart",
                                      "SL.rpartPrune",  "SL.speedglm",  "SL.speedlm",  "SL.step",
                                      "SL.stepAIC",  "SL.step.forward",  "SL.step.interaction",  "SL.svm",
                                      "SL.template",  "SL.xgboost")
  
  #RECURSOS
  options(java.parameters = '-Xmx5g') #Memoria 5GB
  
  
  print('---------------------HYPERPARAMETROS--------------')
  #Explicacion: override default parameters of some functions to fit better
  mtry_seq <- floor(sqrt(ncol(x_train)) * c(1,3,5,8,13)) #MTRY: how many features are randomly chosen within each decision tree node
  print(paste('mtry_seq: ', mtry_seq))
  
  print('Learners modificados (con hyperparametros):')
  learners_rf <- create.Learner(base_learner = "SL.randomForest",
                               params = list(),
                               tune = list(mtry = mtry_seq),
                               verbose = TRUE)
  print(learners_rf)
  
  
  print('------- Algoritmos usados -------')
  algoritmosPredictivosUsados <- list( learners_rf$names, "SL.randomForest", "SL.bayesglm", "SL.caret.rpart", "SL.cforest", "SL.glm", "SL.glmnet",
                                       "SL.lm",  "SL.loess","SL.logreg",  "SL.mean",  "SL.nnet",  "SL.nnls",  "SL.polymars", "SL.ridge",  "SL.rpart")
  print( algoritmosPredictivosTodos )
  
  
  #PENDIENTE: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html#test-algorithm-with-multiple-hyperparameter-settings
  #CROSS_VALIDATION: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html#fit-ensemble-with-external-cross-validation
  
  
  print('-------- MULTICORE-CV (con cross validation) ----------')
print('Se usa para EVALUAR EL RENDIMIENTO: para elegir algoritmos y sus parametros adecuados. Luego habrá que usarlos en un modelo sin CV')
print('Se puede usar la libreria SNOW (Windows, Linux; pero dificil) o multicore (Linux).')
num_cores_disponibles <- RhpcBLASctl::get_num_cores()
num_cores_usados <- (num_cores_disponibles)
print(paste('Uso ', num_cores_usados, ' cores de ', num_cores_disponibles, ' cores disponibles'))
options(mc.cores = num_cores_usados) #Uso todas las CPUs (menos una, para dejar libre el PC para trabajar)
getOption("mc.cores") #En Linux, comprobamos su estamos usando todos los cores

# We need to set a different type of seed that works across cores.
# Otherwise the other cores will go rogue and we won't get repeatable results.
# This version is for the "multicore" parallel system in R.
set.seed(1, "L'Ecuyer-CMRG")

num_v <- 3 # splits the data into V folds and then calls SuperLearner
internal_v <- 2 #inner cross-validation process (replicated across all folds)

print('SUPERLEARNER con MULTICORE:')
print('Con método NNLS (Non-negative Least Squares)')
print(paste('num_v = ', num_v))
print(paste('internal_v = ', internal_v))
print('Esta forma con CV no mide el rendimiento, asi que lo medimos por fuera...')

system.time({
    modelo_multicore_con_cv <- CV.SuperLearner(Y = y_train, X = x_train, family = gaussian(), 
                          parallel = "multicore",
                          SL.library = algoritmosPredictivosUsados, 
                          method = "method.NNLS", verbose = F,
                          cvControl = list(V = num_v, shuffle = FALSE), 
                          innerCvControl = list(list(V = internal_v)), 
                          saveAll = FALSE)
})

library(ggplot2)

print('Modelo:')
print( summary(modelo_multicore_con_cv) )

print('En cada fold, ha ganado este algoritmo:')
table( simplify2array( modelo_multicore_con_cv$whichDiscreteSL ) )
print('En cada fold, cada algoritmo tiene estos pesos:')
modelo_multicore_con_cv$coef
print('Plot the performance with 95% CIs (use a better ggplot theme):')
plot(modelo_multicore_con_cv) + theme_bw()


# Review meta-weights (coefficients) from a CV.SuperLearner object
review_weights <- function(cv_sl) {
  meta_weights = coef(cv_sl)
  means = colMeans(meta_weights)
  sds = apply(meta_weights, MARGIN = 2,  FUN = function(col) { sd(col) })
  mins = apply(meta_weights, MARGIN = 2, FUN = function(col) { min(col) })
  maxs = apply(meta_weights, MARGIN = 2, FUN = function(col) { max(col) })
  # Combine the stats into a single matrix.
  sl_stats = cbind("mean(weight)" = means, "sd" = sds, "min" = mins, "max" = maxs)
  # Sort by decreasing mean weight.
  sl_stats[order(sl_stats[, 1], decreasing = T), ]
}

print(review_weights(modelo_multicore_con_cv), digits = 3)
  
  
  
  
  return(list(modelo_multicore_con_cv, x_test, y_test))
}


############### Para cada distancia, obtengo el mejor modelo #################


out_cortas <- analisis_modelos_superlearner(pasado_ft_cortas)
out_medias <- analisis_modelos_superlearner(pasado_ft_medias)
out_largas <- analisis_modelos_superlearner(pasado_ft_largas)

modelo_cortas <- out_cortas[[1]]
modelo_medias <- out_medias[[1]]
modelo_largas <- out_largas[[1]]

```

Analisis de los modelos ganadores:
```{r}
#' EXPLICACION detallada de un modelo
#'
#' @param modeloInput 
#' @param nombre 
#'
#' @return
#' @export
#'
#' @examples
explicarModelo <- function(modeloInput, nombre){
  
  print(paste('---------- Explicacion del modelo ', nombre, ' -----------'))
  
  print('Tiempo de ejecucion:')
  modeloInput$times$everything
  print('El riesgo del MEJOR modelo (gana el que tiene MENOR riesgo):')
  riesgo_submodelo_ganador <- modeloInput$cvRisk[which.min(modeloInput$cvRisk)]
  print('Resumen:')
  summary(modeloInput)
  print('Riesgo (risk) y peso (coef) de los submodelos utilizados:')
  modeloInput
  
}

explicarModelo(modelo_cortas, 'CORTAS')
#explicarModelo(modelo_medias, 'MEDIAS')
#explicarModelo(modelo_largas, 'LARGAS')

```

Prediccion del futuro usando los modelos ganadores:
```{r}
print('Implementar la prediccion sobre el dataset X futuro (del que no conocemos target)...')
```


