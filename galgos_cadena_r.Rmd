---
title: "GALGOS Cadena en R"
output: html_notebook
---

INPUT: datasets preparados, 
OUTPUT: análisis, datasets elaborados y modelos

Analisis de datasets en proyecto GALGOS.


#### CONFIGURACIONES GENERALES
```{r}
source("/home/carloslinux/Desktop/WORKSPACES/wksp_for_r/r_galgos/galgos_regresion_train_test.R")
establecerConfigGeneral()
```

#### Conexion a BBDD MySQL
```{r}
#Si no tengo acceso a BBDD local, debo tener esto siempre comentado para no pisar el actual CSV
leerDesdeBaseDatosYEscribirCSV("TOTAL", 500)
```

#### Lectura de ficheros CSV (features y targets)
```{r}
print(getwd())
pasado_f <- read.csv('input_features.csv')
pasado_t <- read.csv('input_targets.csv')
pasado_vf <- read.csv('input_validation_features.csv')
```

## ANALISIS PRELIMINAR DE DATOS
```{r}
#Juntar FEATURES y TARGET
pasado_ft <- cbind(pasado_f, pasado_t)

head(pasado_ft)
boxplot(pasado_ft, cex.axis=0.5) 
```
Vemos que hay variables con outliers y otras leptocúrticas (apretadas en torno a la media).
```{r}
#summary(pasado_ft)
lapply(pasado_ft, summary)
```

Creamos un modelo para cada tipo de DISTANCIA, para usar sólo las columnas útiles para esa distancia:
```{r}
#Para quitar las COLUMNAS que no son UTILES para esa DISTANCIA
col_cortas <- c("vel_real_cortas_mediana_norm", "vel_real_cortas_max_norm", "vel_going_cortas_mediana_norm", "vel_going_cortas_max_norm")
col_medias <- c("vel_real_longmedias_mediana_norm", "vel_real_longmedias_max_norm", "vel_going_longmedias_mediana_norm", "vel_going_longmedias_max_norm")
col_largas <- c("vel_real_largas_mediana_norm", "vel_real_largas_max_norm", "vel_going_largas_mediana_norm", "vel_going_largas_max_norm")


# --------------------- TRAIN (+test interno) -------------------
pasado_ft_cortas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_medias | names(pasado_ft) %in% col_largas)] ) #quitar columnas innecesarias
indices_sin_na_cortas <- as.numeric( na.action(pasado_ft_cortas) ) #Indices en los que habia NAs
if (sum( colSums(is.na(pasado_ft_cortas)) ) != 0){ print('ERROR: Hay columnas con missing data!') } #comprobamos que no hay missing data

pasado_ft_medias <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_largas)] )
indices_sin_na_medias <- as.numeric( na.action(pasado_ft_medias) ) #Indices en los que habia NAs
if (sum( colSums(is.na(pasado_ft_medias)) ) != 0){ print('ERROR: Hay columnas con missing data!') } #comprobamos que no hay missing data

pasado_ft_largas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_medias)] )
indices_sin_na_largas <- as.numeric( na.action(pasado_ft_largas) ) #Indices en los que habia NAs
if (sum( colSums(is.na(pasado_ft_largas)) ) != 0){ print('ERROR: Hay columnas con missing data!') } #comprobamos que no hay missing data


paste("CORTAS (train+test):", nrow(pasado_ft_cortas), "x", ncol(pasado_ft_cortas))
paste("MEDIAS (train+test):", nrow(pasado_ft_medias), "x", ncol(pasado_ft_medias))
paste("LARGAS (train+test):", nrow(pasado_ft_largas), "x", ncol(pasado_ft_largas))
```

Analisis de modelos usando SuperLearner:
```{r}
############### Para cada distancia, obtengo el mejor modelo #################
out_cortas <- analisis_modelos_superlearner(pasado_ft_cortas, "CORTAS", FALSE)
out_medias <- analisis_modelos_superlearner(pasado_ft_medias, "MEDIAS", FALSE)
out_largas <- analisis_modelos_superlearner(pasado_ft_largas, "LARGAS", FALSE)

modelo_cortas <- out_cortas[[1]]
modelo_medias <- out_medias[[1]]
modelo_largas <- out_largas[[1]]
```

Guardando los modelos a ficheros:
```{r}
save(modelo_cortas, file = '/home/carloslinux/Desktop/WORKSPACES/wksp_for_r/r_galgos/modelo_cortas_file')
save(modelo_medias, file = '/home/carloslinux/Desktop/WORKSPACES/wksp_for_r/r_galgos/modelo_medias_file')
save(modelo_largas, file = '/home/carloslinux/Desktop/WORKSPACES/wksp_for_r/r_galgos/modelo_largas_file')

rm(modelo_cortas)
rm(modelo_medias)
rm(modelo_largas)
ls() # Compruebo que se han borrado

```

#### VALIDATION (pasado, pero saco el target predicho a un fichero, para enriquecerlo con campos de dinero y comprobar la RENTABILIDAD por fuera)
```{r}
library("SuperLearner")

print(getwd())

# ----------- Modelos ENTRENADOS----------
load(file = "/home/carloslinux/Desktop/WORKSPACES/wksp_for_r/r_galgos/modelo_cortas_file")
load(file = "/home/carloslinux/Desktop/WORKSPACES/wksp_for_r/r_galgos/modelo_medias_file")
load(file = "/home/carloslinux/Desktop/WORKSPACES/wksp_for_r/r_galgos/modelo_largas_file")
ls() # Compruebo que se han cargado

tag <- "TOTAL" #PENDIENTE quitar (coger por parametro)!!!!!!!!!!!!!!


# Las entradas (validation-features) estan divididas en en 3 subsets segun DISTANCIA. Predecimos cada una por separado con su modelo adecuado. Luego juntamos resultados en un solo dataset de salida, pero manteniendo el ORDEN (PENDIENTE conocemos los índices, para reconstruir el orden)!!!!!!!!!


# ---------------Entradas (validation features: mantener el ORDEN)-----------
#anhado un indice, para poder recuperar el ORDEN al final
pasado_vf$INDICE_ORDEN <- seq.int(nrow(pasado_vf))

pasado_vf_cortas <- na.omit( subset(pasado_vf[, !(names(pasado_vf) %in% col_medias | names(pasado_vf) %in% col_largas)], distancia_norm <= 0.33) )
pasado_vf_medias <- na.omit( subset(pasado_vf[, !(names(pasado_vf) %in% col_cortas | names(pasado_vf) %in% col_largas)], distancia_norm > 0.33 & distancia_norm <= 0.66) )
pasado_vf_largas <- na.omit( subset(pasado_vf[, !(names(pasado_vf) %in% col_cortas | names(pasado_vf) %in% col_medias)], distancia_norm > 0.66) )

paste("CORTAS-VF (sin NAs):", nrow(pasado_vf_cortas), "x", ncol(pasado_vf_cortas))
paste("MEDIAS-VF (sin NAs):", nrow(pasado_vf_medias), "x", ncol(pasado_vf_medias))
paste("LARGAS-VF (sin NAs):", nrow(pasado_vf_largas), "x", ncol(pasado_vf_largas))

#PENDIENTE Atencion, hemos quitado filas que tenian valores NAs. Al final, tenemos que meter esas filas, con cuidado de mantener el orden y los huecos.


#Prediccion CORTAS
predicciones_vt_model_cortas <- predict.SuperLearner(object = modelo_cortas, newdata = subset(pasado_vf_cortas, select = -c(INDICE_ORDEN)), onlySL = TRUE) #No usa los que tienen peso =0
predicciones_vt_cortas <- predicciones_vt_model_cortas$pred #Prediccion
print(paste("PREDICCION CORTAS =", length(predicciones_vt_cortas)))

#Prediccion MEDIAS
predicciones_vt_model_medias <- predict.SuperLearner(object = modelo_medias, newdata = subset(pasado_vf_medias, select = -c(INDICE_ORDEN)), onlySL = TRUE) #No usa los que tienen peso =0
predicciones_vt_medias <- predicciones_vt_model_medias$pred #Prediccion
print(paste("PREDICCION MEDIAS =", length(predicciones_vt_medias)))

#Prediccion LARGAS
predicciones_vt_model_largas <- predict.SuperLearner(object = modelo_largas, newdata = subset(pasado_vf_largas, select = -c(INDICE_ORDEN)), onlySL = TRUE) #No usa los que tienen peso =0
predicciones_vt_largas <- predicciones_vt_model_largas$pred #Prediccion
print(paste("PREDICCION LARGAS =", length(predicciones_vt_largas)))


# CBIND: entrada(con orden) + salida
pasado_vft_cortas <- cbind(pasado_vf_cortas, predicciones_vt_cortas)
pasado_vft_medias <- cbind(pasado_vf_medias, predicciones_vt_medias)
pasado_vft_largas <- cbind(pasado_vf_largas, predicciones_vt_largas)
#Juntamos cortas, medias y largas
pasado_vft <- rbind( rbind(pasado_vft_cortas, pasado_vft_medias), pasado_vft_largas)
# Rellenamos las  filas que eran NAs

#Ordenamos por INDICE_ORDEN


path_validation_targets <- paste("/home/carloslinux/Desktop/DATOS_LIMPIO/galgos/pasado_validation_targets_predichos_", tag, ".txt")
#save(out_multicore_simple_predicho, file = path_validation_targets)

```

#### PREDICCION del FUTURO usando los modelos ganadores:


```{r}
print('Implementar la prediccion sobre el dataset X futuro (del que no conocemos target)...')

```

