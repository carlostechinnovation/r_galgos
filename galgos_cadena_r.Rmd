---
title: "GALGOS Cadena en R"
output: html_notebook
---

INPUT: datasets preparados, 
OUTPUT: análisis, datasets elaborados y modelos

Analisis de datasets en proyecto GALGOS.

#### Conexion a BBDD MySQL
```{r}
library(RMySQL)
library(DBI)

#' Conexion a base de datos para LECTURA MASIVA y escritura a CSV.
#'
#' @return
#' @export
#'
#' @examples
leerDesdeBaseDatosYEscribirCSV <- function(){
  
  # ---------------Conexion a BBDD ------------
  #Conexiones ya abiertas
  conexiones_abiertas <- dbListConnections(MySQL())
  #Cerramos las conexiones abiertas
  #dbDisconnect(dbListConnections(MySQL())[[1]])

  mydb = dbConnect(MySQL(), user = 'root', password = 'datos1986', dbname = 'datos_desa', host = 'localhost')
  on.exit(dbDisconnect(mydb))
  #dbListTables(mydb)  #Todas las tablas que tengo
  
  
  # ------------- Features (INPUT) -----------------------
  pasado_f_rs <- dbSendQuery(mydb, "SELECT * FROM datos_desa.tb_ds_pasado_train_features_TOTAL LIMIT 10000")
  typeof(pasado_f_rs)
  pasado_f <- dbFetch(pasado_f_rs, n = -1)
  #dbClearResult(pasado_f_rs)

  #EXCEPCION Quito columna mes
  mes_indice <- which( colnames(pasado_f) == "mes_norm" )
  pasado_f <- pasado_f[, -mes_indice]
  
  attach(pasado_f)
  names(pasado_f)
  print(paste("FEATURE MATRIX: ", nrow(pasado_f), "x", ncol(pasado_f)))
  print(typeof(pasado_f)) #Formato: lista

  
  # -------------------- Targets (INPUT) -----------------
  pasado_t_rs <- dbSendQuery(mydb, "SELECT * FROM datos_desa.tb_ds_pasado_train_targets_TOTAL LIMIT 10000")
  typeof(pasado_t_rs)
  pasado_t <- dbFetch(pasado_t_rs, n = -1)
  #dbClearResult(pasado_t_rs)
  attach(pasado_t)
  names(pasado_t)
  print(paste("TARGET MATRIX: ", nrow(pasado_t), "x", ncol(pasado_t)))
  print(typeof(pasado_t))


  # ----- Escritura a fichero CSV (para poder trabajar en PCs donde no tengo montada la BBDD con datos) ----
  print(getwd())
  write.csv(x = pasado_f, file = 'input_features.csv', append = FALSE, quote = TRUE, sep = '|', eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE, qmethod = c("escape", "double"), fileEncoding = "UTF-8")
  write.csv(x = pasado_t, file = 'input_targets.csv', append = FALSE, quote = TRUE, sep = '|', eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE, qmethod = c("escape", "double"), fileEncoding = "UTF-8")

}

#Si no tengo acceso a BBDD local, debo tener esto siempre comentado para no pisar el actual CSV
#leerDesdeBaseDatosYEscribirCSV()
```

#### Lectura de ficheros CSV (features y targets)
```{r}
print(getwd())
pasado_f <- read.csv('input_features.csv')
pasado_t <- read.csv('input_targets.csv')
```

## ANALISIS PRELIMINAR DE DATOS
```{r}
#Juntar FEATURES y TARGET
pasado_ft <- cbind(pasado_f, pasado_t)

head(pasado_ft)
boxplot(pasado_ft, cex.axis=0.5) 
```
Vemos que hay variables con outliers y otras leptocúrticas (apretadas en torno a la media).
```{r}
#summary(pasado_ft)
lapply(pasado_ft, summary)
```

Creamos un modelo para cada tipo de DISTANCIA, para usar sólo las columnas útiles para esa distancia:
```{r}
col_cortas <- c("vel_real_cortas_mediana_norm", "vel_real_cortas_max_norm", "vel_going_cortas_mediana_norm", "vel_going_cortas_max_norm")
col_medias <- c("vel_real_longmedias_mediana_norm", "vel_real_longmedias_max_norm", "vel_going_longmedias_mediana_norm", "vel_going_longmedias_max_norm")
col_largas <- c("vel_real_largas_mediana_norm", "vel_real_largas_max_norm", "vel_going_largas_mediana_norm", "vel_going_largas_max_norm")

#QUITAR las COLUMNAS que no son UTILES para esa DISTANCIA
pasado_ft_cortas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_medias | names(pasado_ft) %in% col_largas)] )
colSums(is.na(pasado_ft_cortas)) #comprobamos que no hay missing data
indices_sin_na_cortas <- as.numeric( na.action(pasado_ft_cortas) )
paste("CORTAS:", nrow(pasado_ft_cortas), "x", ncol(pasado_ft_cortas))

pasado_ft_medias <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_largas)] )
colSums(is.na(pasado_ft_medias)) #comprobamos que no hay missing data
indices_sin_na_medias <- as.numeric( na.action(pasado_ft_medias) )
paste("MEDIAS:", nrow(pasado_ft_medias), "x", ncol(pasado_ft_medias))

pasado_ft_largas <- na.omit( pasado_ft[, !(names(pasado_ft) %in% col_cortas | names(pasado_ft) %in% col_medias)] )
colSums(is.na(pasado_ft_largas)) #comprobamos que no hay missing data
indices_sin_na_largas <- as.numeric( na.action(pasado_ft_largas) )
paste("LARGAS:", nrow(pasado_ft_largas), "x", ncol(pasado_ft_largas))
```


Analisis de MODELOS de forma directa (sin SuperLearner):
```{r}
#' SELECCION DEL MODELO DE FORMA MANUAL
#'
#' @param matrizentrada 
#'
#' @return
#' @export
#'
#' @examples
analisis_modelos <- function(matrizentrada){
  library(e1071) #SVM
  library(rpart) #Regression trees
  
  ## Split en Datasets (train y test)
  index     <- 1:nrow(matrizentrada)
  tercio <- trunc(0.30 * length(index)) #70%-TRAIN, 30%-Test
  testindex <- sample(index, tercio, replace = FALSE, prob = NULL)
  testset   <- na.omit(matrizentrada[testindex,]) #TEST Quita las filas que tengan ALGUN valor NA
  trainset  <- na.omit(matrizentrada[-testindex,])#TRAIN Quita las filas que tengan ALGUN valor NA
  
  #Columna TARGET
  indice_target <- which( colnames(trainset) == "TARGET" )
  
  ## svm (MAQUINAS VECTOR SOPORTE) para REGRESIÓN NO LINEAL
  svm.model <- svm(formula = TARGET ~ ., data = trainset, cost = 1000, gamma = 0.0001)
  svm.pred  <- predict(svm.model, testset[,-indice_target])
  svm_error <- crossprod(svm.pred - testset[,indice_target]) / length(testindex)
  svm_error
  
  ## rpart (ARBOLES DE REGRESION) para REGRESIÓN NO LINEAL
  rpart.model <- rpart(formula = TARGET ~ ., data = trainset)
  rpart.pred  <- predict(rpart.model, testset[,-indice_target])
  rpart_error <- crossprod(rpart.pred - testset[,indice_target]) / length(testindex)
  rpart_error
  
  if ( svm_error < rpart_error ) {
    print("Gana modelo SVM")
    return(svm.model)
  } else {
    print("Gana modelo RPART")
    return( rpart.model )
  }
}



############### Para cada distancia, obtengo el mejor modelo #################
#modelo_cortas <- analisis_modelos(pasado_ft_cortas)
#modelo_medias <- analisis_modelos(pasado_ft_medias)
#modelo_largas <- analisis_modelos(pasado_ft_largas)


```


Analisis de modelos usando SuperLearner:
```{r}
#' SELECCION DEL MODELO USANDO SUPERLEARNER
#'
#' @param matrizentrada 
#'
#' @return
#' @export
#'
#' @examples
analisis_modelos_superlearner <- function(matrizentrada){
  
  library("SuperLearner")
  
  ## Split en Datasets (train y test)
  index     <- 1:nrow(matrizentrada)
  tercio <- trunc(0.30 * length(index)) #70%-TRAIN, 30%-Test
  testindex <- sample(index, tercio, replace = FALSE, prob = NULL)
  testset   <- na.omit(matrizentrada[testindex,]) #TEST Quita las filas que tengan ALGUN valor NA
  trainset  <- na.omit(matrizentrada[-testindex,])#TRAIN Quita las filas que tengan ALGUN valor NA
  
  #Columna TARGET
  indice_target <- which( colnames(trainset) == "TARGET" )
  
  #Features y target de los datasets de TRAIN y TEST
  x_train <- subset(trainset, select = -indice_target)
  y_train <- trainset$TARGET
  x_test <- subset(testset, select = -indice_target)
  y_test <- testset$TARGET
  
  #Estructura y dimensiones de los datos
  #str(x_train)
  #dim(x_train)
  
  #MODELOS DISPONIBLES:
  #listWrappers()
  
  set.seed(150)
  
  algoritmosPredictivosTodos <- list("SL.bartMachine", "SL.bayesglm",  "SL.biglasso",  "SL.caret",
                                      "SL.caret.rpart",  "SL.cforest", "SL.dbarts",  "SL.earth",
                                      "SL.extraTrees",  "SL.gam",  "SL.gbm",  "SL.glm",  "SL.glm.interaction",
                                      "SL.glmnet",  "SL.ipredbagg",   "SL.kernelKnn",  "SL.knn",
                                      "SL.ksvm",  "SL.lda",  "SL.leekasso",  "SL.lm",  "SL.loess",
                                      "SL.logreg",  "SL.mean",  "SL.nnet",  "SL.nnls",  "SL.polymars",
                                      "SL.qda",  "SL.randomForest",  "SL.ranger",  "SL.ridge",  "SL.rpart",
                                      "SL.rpartPrune",  "SL.speedglm",  "SL.speedlm",  "SL.step",
                                      "SL.stepAIC",  "SL.step.forward",  "SL.step.interaction",  "SL.svm",
                                      "SL.template",  "SL.xgboost")
  
  #RECURSOS
  options(java.parameters = '-Xmx5g') #Memoria 5GB
  
  
  print('---------------------HYPERPARAMETROS--------------')
  #Explicacion: override default parameters of some functions to fit better
  mtry_seq <- floor(sqrt(ncol(x_train)) * c(1,2,3)) #MTRY: how many features are randomly chosen within each decision tree node
  print(paste('mtry_seq: ', mtry_seq))
  
  print('Learners modificados (con hyperparametros):')
  learners_rf <- create.Learner(base_learner = "SL.randomForest",
                               params = list(),
                               tune = list(mtry = mtry_seq),
                               verbose = TRUE)
  print(learners_rf)
  
  
  print('------- Algoritmos usados -------')
  algoritmosPredictivosUsados <- list(
    # learners_rf$names,
    "SL.randomForest", "SL.ridge", "SL.nnet"
    )
  print( algoritmosPredictivosUsados )
  
  
  #PENDIENTE: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html#test-algorithm-with-multiple-hyperparameter-settings
  
  
  #--------------------------------------------------------------- 
  # print('UNICORE (con cross validation)...')
  # modelo_super <- SuperLearner(Y = y_train, X = x_train, family = gaussian(), 
  #                              SL.library = algoritmosPredictivosUsados, method = "method.NNLS",
  #                              id = NULL, verbose = TRUE,
  #                              control = list(), cvControl = list(), obsWeights = NULL, env = parent.frame())
  # 
  # summary(modelo_super)
  
  
  #------------------------------------------------------------
  print('------ MULTICORE (con cross validation)... -------')
  print('Se puede usar la libreria SNOW (Windows, Linux; pero dificil) o multicore (Linux).')
  num_cores_disponibles <- RhpcBLASctl::get_num_cores()
  num_cores_usados <- (num_cores_disponibles)
  print(paste('Uso ', num_cores_usados, ' cores de ', num_cores_disponibles, ' cores disponibles'))
  options(mc.cores = num_cores_usados) #Uso todas las CPUs (menos una, para dejar libre el PC para trabajar)
  getOption("mc.cores") #En Linux, comprobamos su estamos usando todos los cores

  # We need to set a different type of seed that works across cores.
  # Otherwise the other cores will go rogue and we won't get repeatable results.
  # This version is for the "multicore" parallel system in R.
  set.seed(1, "L'Ecuyer-CMRG")

  #Numero de subsets para hacer la cross-validation
  num_v <- 2
  
  # While this is running check CPU using in Activity Monitor / Task Manager.
  print('SUPERLEARNER con MULTICORE:')
  print('Con método NNLS (Non-negative Least Squares)')
  print('Esta forma con CV no mide el rendimiento, asi que lo medimos por fuera')
  system.time({
    modelo_multicore_con_cv <- CV.SuperLearner(Y = y_train, X = x_train, family = gaussian(), 
                          parallel = "multicore",
                          SL.library = algoritmosPredictivosUsados, 
                          method = "method.NNLS", verbose = F,
                          cvControl = list(V = num_v, shuffle=FALSE), 
                          innerCvControl = list(list(V = 2)), 
                          saveAll=FALSE)
  })
  
  print( summary(modelo_multicore_con_cv) )
  plot(modelo_multicore_con_cv)
  
  # Review the distribution of the best single learner as external CV folds
  table( simplify2array( modelo_multicore_con_cv$whichDiscreteSL ) )
  # Plot the performance with 95% CIs (use a better ggplot theme)
  plot(modelo_multicore_con_cv) + theme_bw()

  
  #------------------------------------------------------------------
  # print('MULTICORE (sin cross validation)...')
  # # Set multicore compatible seed.
  # set.seed(1, "L'Ecuyer-CMRG")
  # # Fit the SuperLearner.
  # modelo_multicore_sin_cv = mcSuperLearner(Y = y_train, X = x_train, family = gaussian(),
  #                   SL.library = algoritmosPredictivosUsados, verbose = TRUE)
  # summary(modelo_multicore_sin_cv)
  
  # ----------------------------------------------
  
  #CROSS_VALIDATION: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html#fit-ensemble-with-external-cross-validation
  
  
  #--------------------------------------------------------------- 
  # print('Validando modelo UNICORE (con cross validation) sobre dataset de test...')
  # validarModelo(modelo_super, x_test, y_test, "UNICORE_CON_CV")
  print('Validando modelo MULTICORE (con cross validation) sobre dataset de test...')
  validarModelo(modelo_multicore_con_cv, x_test, y_test, "MULTICORE_CON_CV")
  # print('Validando modelo MULTICORE (sin cross validation) sobre dataset de test...')
  # validarModelo(modelo_multicore_sin_cv, x_test, y_test, "MULTICORE_SIN_CV")
  
  
  return(modelo_multicore_con_cv)
}


#' VALIDACION del modelo ENTRENADO usando dataset de TEST. Obtengo porcentaje de acierto.
#'
#' @param modeloEntrenado 
#' @param x_text 
#' @param y_test 
#' @param tipo 
#'
#' @return
#' @export
#'
#' @examples
validarModelo <- function(modeloEntrenado, x_test, y_test, tipo){
  
  print('-------------- VALIDACION ---------------')
  print('Usando dataset de test para validar el modelo y obtener porcentaje de aciertoPREDICCION sobre datos test (validacion)...')
  print(paste('Tipo: ', tipo))
  print( paste("VALIDACION-INPUTS:", "  x_test=",nrow(x_test), "x", ncol(x_test),  "   y_test=",nrow(x_test), "x", ncol(x_test)) )
  
  if (tipo == "UNICORE_CON_CV") {
    
    y_test_predicho_objeto <- predict.SuperLearner(object = modeloEntrenado, newdata = x_test, onlySL = TRUE) #No usa los que tienen peso =0
    
    print('str (descripcion y filas de ejemplo):')
    str(y_test_predicho_objeto)
    head(y_test_predicho_objeto)
    print('summary:')
    summary(y_test_predicho_objeto$library.predict)
    
    #Graficos de la prediccion
    library(ggplot2)
    qplot(y_test_predicho_objeto$pred[, 1]) + theme_minimal() #Histograma de los valores predichos
    qplot(y_test, y_test_predicho_objeto$pred[, 1]) + theme_minimal() #Scatterplot
    
    #ROC (Solo para CLASIFICACION BINARIA)
    # Curva ROC (AUC, Area Under Curve): AUC can range from 0.5 (no better than chance) to 1.0 (perfect)
    #pred_rocr <- ROCR::prediction(predictions=y_test_predicho_objeto$pred, labels = y_test, label.ordering = NULL)
    #auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
    #print(auc)
    
     
  } else if (tipo == "MULTICORE_CON_CV") {
    
    
    num_v <- modeloEntrenado$V
    print(paste('El modelo usó CV con V folds: ', num_v))
    
    print("Coeficientes por algoritmo y fold (muestro 10 filas):")
    head( coef(test) )
    
    y_test_predicho_objeto <- modeloEntrenado$SL.predict
    print(paste("y_test_predicho_objeto: ", y_test_predicho_objeto))
    
    
    
    plot( 
      y_test[ modeloEntrenado$folds[[num_v]] ], #target RELA (test)
      y_test_predicho_objeto, #target predicho
      xlab = "Actual", ylab = "Predicted",
      main = paste('Fold numero ', num_v)
      )  
    
    
    print('str PREDICHO (descripcion y filas de ejemplo):')
    str(y_test_predicho_objeto)
    print( head(y_test_predicho_objeto) )
    
    print('str TEST (lo esperable):')
    str(y_test)
    print( head(y_test_predicho_objeto) )
    
    
    
    if(length(y_test_predicho_objeto) != length(y_test)){
      print('Deberian tener las mismas dimensiones!!!!! COMPROBARLO!!!')
      
    } else {
      #Graficos de la prediccion
      library(ggplot2)
      qplot(y_test_predicho_objeto) + theme_minimal() #Histograma de los valores predichos
      qplot(y_test, y_test_predicho_objeto) + theme_minimal() #Scatterplot
      
    }
    
  
    
    
  } else if(tipo == "MULTICORE_SIN_CV"){
    
  }
  
  
}



############### Para cada distancia, obtengo el mejor modelo #################

modelo_cortas <- analisis_modelos_superlearner(pasado_ft_cortas)
#modelo_medias <- analisis_modelos_superlearner(pasado_ft_medias)
#modelo_largas <- analisis_modelos_superlearner(pasado_ft_largas)

```

Analisis de los modelos ganadores:
```{r}
#' EXPLICACION detallada de un modelo
#'
#' @param modeloInput 
#' @param nombre 
#'
#' @return
#' @export
#'
#' @examples
explicarModelo <- function(modeloInput, nombre){
  
  print(paste('---------- Explicacion del modelo ', nombre, ' -----------'))
  
  print('Tiempo de ejecucion:')
  modeloInput$times$everything
  print('El riesgo del MEJOR modelo (gana el que tiene MENOR riesgo):')
  riesgo_submodelo_ganador <- modeloInput$cvRisk[which.min(modeloInput$cvRisk)]
  print('Resumen:')
  summary(modeloInput)
  print('Riesgo (risk) y peso (coef) de los submodelos utilizados:')
  modeloInput
  
}

explicarModelo(modelo_cortas, 'CORTAS')
#explicarModelo(modelo_medias, 'MEDIAS')
#explicarModelo(modelo_largas, 'LARGAS')

```

Prediccion del futuro usando los modelos ganadores:
```{r}
print('Implementar la prediccion sobre el dataset X futuro (del que no conocemos target)...')
```


